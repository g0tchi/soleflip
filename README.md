# SoleFlipper 

[![Version](https://img.shields.io/badge/version-2.2.0-blue.svg)](https://github.com/yourusername/soleflip)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.11+-blue.svg)](https://python.org)
[![PostgreSQL](https://img.shields.io/badge/postgresql-15+-blue.svg)](https://postgresql.org)

> **Professional Sneaker Resale Management System with Advanced Brand Intelligence**

SoleFlipper is a comprehensive sneaker resale management platform featuring advanced analytics, brand intelligence, and automated data processing capabilities. Built for serious resellers and businesses managing high-volume sneaker transactions.

## ðŸš€ Docker-based Setup (Recommended)

This is the recommended way to run the entire SoleFlipper stack, including the API, database, Metabase, and n8n.

### Prerequisites
- Docker and Docker Compose installed on your system.

### 1. Configure Environment
First, create a `.env` file for your configuration. You can copy the provided example file:
```bash
cp .env.example .env
```
Now, open the `.env` file in a text editor and **set a secure `FIELD_ENCRYPTION_KEY`**. You can generate one with this command:
```bash
python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
```
The `DATABASE_URL` in the `.env.example` is already configured for this Docker setup.

### 2. Run the Stack
With the `.env` file configured, start all services using Docker Compose:
```bash
docker-compose up --build -d
```
- `--build` will build the API image for the first time.
- `-d` will run the services in the background.

### 3. Accessing Services
- **SoleFlipper API**: `http://localhost:8000`
- **API Docs**: `http://localhost:8000/docs`
- **Metabase**: `http://localhost:6400`
- **n8n**: `http://localhost:5678`
- **Adminer (Database GUI)**: `http://localhost:8220`

The first time you run the stack, the API service will automatically run database migrations.

### 4. Initial Setup (StockX API)
To use the StockX features, you need to perform a one-time setup to get your API credentials. Follow the detailed guide here:
> **StockX Setup Guide:** [`docs/guides/stockx_auth_setup.md`](docs/guides/stockx_auth_setup.md)

## ðŸ—ï¸ Architecture

### Core Components

- **ðŸ”§ Core Application** (`main.py`, `pyproject.toml`) - FastAPI application with async support
- **ðŸ¢ Business Logic** (`domains/`) - Modular domain-driven architecture
- **ðŸ› ï¸ Utilities** (`scripts/`) - Database, analytics, and processing scripts  
- **ðŸ“Š Data Management** (`data/`) - Backups, samples, and development data
- **âš™ï¸ Configuration** (`config/`) - N8N workflows and external service configs
- **ðŸ“ˆ Analytics** (`sql/`) - Dashboard queries and database improvements
- **ðŸ“š Documentation** (`docs/`) - Comprehensive guides and API documentation

### Directory Structure

```
soleflip/
â”œâ”€â”€ ðŸŽ¯ Core Files
â”‚   â”œâ”€â”€ main.py              # FastAPI application entry point
â”‚   â”œâ”€â”€ pyproject.toml       # Project configuration and dependencies
â”‚   â””â”€â”€ docker-compose.yml   # Docker services configuration
â”‚
â”œâ”€â”€ ðŸ¢ Business Logic
â”‚   â”œâ”€â”€ domains/             # Domain-driven architecture (DDD)
â”‚   â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ inventory/
â”‚   â”‚   â”œâ”€â”€ products/
â”‚   â”‚   â””â”€â”€ sales/
â”‚   â”‚
â”‚   â”œâ”€â”€ shared/              # Shared utilities (DB connection, models)
â”‚   â””â”€â”€ migrations/          # Database schema migrations
â”‚
â”œâ”€â”€ ðŸ› ï¸ Scripts & Utilities
â”‚   â”œâ”€â”€ scripts/             # Admin, setup, and operational scripts
â”‚   â”œâ”€â”€ data/                # Sample data and backups
â”‚   â””â”€â”€ sql/                 # SQL for improvements, etc.
â”‚
â”œâ”€â”€ âš™ï¸ Configuration & Analytics
â”‚   â”œâ”€â”€ config/              # Configs for n8n, API docs, etc.
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ n8n/
â”‚   â”‚
â”‚   â””â”€â”€ metabase/            # Metabase queries, views, and dashboards
â”‚       â”œâ”€â”€ queries/
â”‚       â””â”€â”€ views/
â”‚
â”œâ”€â”€ ðŸ“š Documentation
â”‚   â”œâ”€â”€ docs/
â”‚       â”œâ”€â”€ setup/
â”‚       â””â”€â”€ guides/
â”‚
â””â”€â”€ ðŸ§ª Testing
    â””â”€â”€ tests/               # Unit, integration, and API tests
```

## âœ¨ Key Features

### ðŸ†• Recent Features (v2.2.0)
- **ðŸš€ QuickFlip Arbitrage System**: Automated detection of profitable arbitrage opportunities across platforms
- **ðŸ’¼ Budibase Integration**: Low-code business application for visual StockX API management
- **ðŸ­ Supplier Management**: Complete supplier account import and management system
- **ðŸ³ Enhanced Docker Infrastructure**: Production-ready Synology NAS deployment support
- **ðŸ“ˆ StockX API Enhancements**: Comprehensive gap analysis and improved endpoint validation

### ðŸ§  Brand Intelligence System
- **Deep Brand Analytics**: Comprehensive brand profiles with founder info, financial data, sustainability scores.
- **Historical Timeline**: Track major brand milestones and innovation events.
- **Collaboration Tracking**: Analyze partnership success with metrics and hype scores.
- **Cultural Impact Analysis**: Brand influence scoring and tier classification.
- **Financial Performance**: Multi-year revenue, growth, and profitability analysis.

### ðŸ“Š Advanced Analytics
- **Executive Dashboards**: High-level KPIs and performance metrics.
- **Metabase Integration**: Pre-built dashboards and queries for immediate insights. See `metabase/` for details.
- **Real-time Analytics**: Live transaction and inventory tracking.

### ðŸ”„ Data Processing & Automation
- **StockX API Integration**: Automated, scheduled fetching of orders from the StockX API with OAuth2 support.
- **N8N Workflows**: Pre-built workflows in `config/n8n/` for data synchronization and automation.
- **Legacy CSV Imports**: Robust processing pipeline with validation and transformation.

### ðŸ—„ï¸ Robust Backend
- **PostgreSQL Database**: Strong, relational database with an advanced, multi-schema architecture.
- **Automated Backups**: Reliable, scheduled backups with integrity checks using the `scripts/database/create_backup.py` script.
- **Alembic Migrations**: Keeps the database schema versioned and in sync.

## ðŸ“‹ Prerequisites

- **Docker & Docker Compose**: For running the entire application stack.
- **Python 3.11+**: For running helper scripts locally.

## ðŸ”§ Configuration

### Database & Services
The application is configured using environment variables. Copy the example file and customize it for your environment:
```bash
cp .env.example .env
```
Key variables to configure in your `.env` file:
- `DATABASE_URL`: Connection string for your PostgreSQL database.
- `FIELD_ENCRYPTION_KEY`: A secret key for encrypting sensitive data. Generate one with: `python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"`

### StockX & n8n API Keys
For full functionality, you need to configure API credentials for StockX and n8n.

1.  **StockX API**: The application requires OAuth2 credentials to fetch data from StockX. Follow the detailed guide to get your `client_id`, `client_secret`, and `refresh_token`.
    > **Full Guide**: [`docs/guides/stockx_auth_setup.md`](docs/guides/stockx_auth_setup.md)

2.  **n8n Workflows**: The workflows in `config/n8n/` may require API keys or other credentials to be configured within the n8n UI. See the guides in `docs/guides/n8n_integration/` for more details.

## ðŸ“Š Analytics & Dashboards (Metabase)

This project is designed for deep analytics using Metabase. We provide pre-built assets to get you started quickly.

-   **Dashboard Import File**: A ready-to-import Metabase dashboard file is located at `metabase/metabase_dashboards.json`.
-   **Dashboard SQL Queries**: The powerful SQL queries that power the dashboards can be found in `metabase/queries/brand_dashboard_sql_queries.sql`. These can be used for reference or to build your own custom dashboards.

For instructions on setting up Metabase and importing these assets, see the guide:
> **Setup Guide**: [`docs/metabase_setup_guide.md`](docs/metabase_setup_guide.md)

## ðŸš€ Usage Examples

### Import Sales Data
```bash
# To process a legacy CSV sales report:
python domains/integration/api/webhooks.py --import sales_data.csv
```

### Run a Database Health Check
```bash
# Verify database integrity and get statistics:
python scripts/database/check_database_integrity.py
```

### Create a Backup
```bash
# Create a comprehensive, verified database backup:
python scripts/database/create_backup.py
```
This will create a backup file and a `restore_backup.sh` script in the same directory for easy recovery.

### Restore from a Backup
```bash
# To restore, run the generated shell script:
cd scripts/database/
./restore_backup.sh
```

## ðŸ§ª Testing

The project has a comprehensive test suite.
```bash
# Run all tests
pytest

# Run specific test categories (unit, integration)
pytest -m unit
pytest -m integration

# Generate a test coverage report
pytest --cov=domains --cov-report=html
```

## ðŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1.  **Fork the repository.**
2.  Create a new feature branch (`git checkout -b feature/my-new-feature`).
3.  Commit your changes (`git commit -m 'Add some feature'`).
4.  Push to the branch (`git push origin feature/my-new-feature`).
5.  **Open a Pull Request.**

Please ensure your code follows PEP 8, includes tests for new features, and updates documentation where necessary.

## ðŸ“‹ Changelog

All notable changes to this project are documented in the `CHANGELOG.md` file.
> **[View the full Changelog](CHANGELOG.md)**

## ðŸ“ž Support & Contact

-   **Documentation**: For detailed guides on setup, features, and architecture, please browse the `docs/` directory.
-   **Bug Reports & Feature Requests**: If you encounter a bug or have an idea for a new feature, please open an issue on GitHub.
-   **General Questions**: For general questions and community discussions, please use the GitHub Discussions section.

## ðŸ“„ License

This project is licensed under the MIT License - see the `LICENSE` file for details.
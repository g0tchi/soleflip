import logging\n"""\nCommerce Intelligence Platform API Router\nHandles enterprise data sources including Awin, retailers, and commerce platforms.\n"""\n\nimport io\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import List, Optional\nfrom uuid import UUID, uuid4\n\nimport structlog\nfrom fastapi import APIRouter, Depends, File, Form, HTTPException, UploadFile\nfrom pydantic import BaseModel\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom domains.integration.services.awin_connector import AwinConnector\nfrom domains.integration.services.large_retailer_service import LargeRetailerImportService, create_retailer_import_service\nfrom shared.auth.dependencies import require_admin_role\nfrom shared.database.connection import get_db_session\n\nlogger = structlog.get_logger(__name__)\n\nrouter = APIRouter(prefix="/api/v1/commerce-intelligence", tags=["Commerce Intelligence Platform"])\n\n\n# Response Models\nclass CommerceUploadResponse(BaseModel):\n    success: bool\n    batch_id: str\n    message: str\n    source_type: str\n    estimated_records: Optional[int] = None\n\n\nclass CommerceSourceInfo(BaseModel):\n    source_id: str\n    source_name: str\n    source_type: str\n    description: str\n    supported_formats: List[str]\n    max_file_size_mb: int\n    features: List[str]\n\n\nclass CommerceBatchStatus(BaseModel):\n    batch_id: str\n    source_type: str\n    status: str\n    progress: float\n    processed_records: int\n    failed_records: int\n    total_records: Optional[int]\n    memory_usage_mb: float\n    current_stage: str\n    error_message: Optional[str]\n    created_at: str\n    completed_at: Optional[str]\n\n\n# Request Models\nclass AwinImportRequest(BaseModel):\n    file_path: str\n    import_name: Optional[str] = None\n\n\n@router.get("/sources", response_model=List[CommerceSourceInfo])\nasync def get_commerce_sources():\n    """Get all available commerce data sources"""\n    \n    sources = [\n        CommerceSourceInfo(\n            source_id="awin",\n            source_name="Awin Affiliate Network",\n            source_type="affiliate",\n            description="Import transaction data, commission reports, and advertiser information from Awin",\n            supported_formats=["csv", "tab-delimited"],\n            max_file_size_mb=500,\n            features=[\n                "Transaction data processing",\n                "Commission tracking", \n                "Advertiser analytics",\n                "Publisher performance",\n                "Bulk data validation"\n            ]\n        ),\n        CommerceSourceInfo(\n            source_id="nike",\n            source_name="Nike Retailer",\n            source_type="retailer",\n            description="Enterprise Nike product catalog and inventory data",\n            supported_formats=["csv", "json", "jsonl"],\n            max_file_size_mb=1000,\n            features=[\n                "Product catalog processing",\n                "Inventory management",\n                "Pricing intelligence",\n                "Release calendar data"\n            ]\n        ),\n        CommerceSourceInfo(\n            source_id="adidas",\n            source_name="Adidas Retailer", \n            source_type="retailer",\n            description="Adidas product data and market intelligence",\n            supported_formats=["csv", "json", "jsonl"],\n            max_file_size_mb=1000,\n            features=[\n                "Product catalog processing",\n                "Market trend analysis",\n                "Inventory optimization",\n                "Price monitoring"\n            ]\n        )\n    ]\n    \n    return sources\n\n\n@router.post("/upload/awin", response_model=CommerceUploadResponse)\nasync def upload_awin_data(\n    file: UploadFile = File(...),\n    import_name: Optional[str] = Form(None),\n    db_session: AsyncSession = Depends(get_db_session),\n    current_user = Depends(require_admin_role)\n):\n    """Upload Awin affiliate data for processing"""\n    \n    if not file.filename.endswith(('.csv', '.txt')):\n        raise HTTPException(status_code=400, detail="Only CSV and tab-delimited files are supported for Awin")\n    \n    # Check file size (max 500MB for Awin)\n    if file.size and file.size > 500 * 1024 * 1024:\n        raise HTTPException(status_code=400, detail="File too large. Maximum size is 500MB for Awin imports")\n    \n    batch_id = uuid4()\n    \n    try:\n        # Save uploaded file temporarily\n        file_content = await file.read()\n        temp_file_path = f"/tmp/awin_import_{batch_id}_{file.filename}"\n        \n        with open(temp_file_path, "wb") as temp_file:\n            temp_file.write(file_content)\n        \n        # Use Awin Connector for processing\n        awin_connector = AwinConnector(db_session)\n        batch = await awin_connector.run_import(Path(temp_file_path))\n        \n        logger.info(\n            "Awin import completed successfully",\n            batch_id=str(batch.id),\n            filename=file.filename,\n            processed_records=batch.processed_records,\n            error_records=batch.error_records\n        )\n        \n        # Clean up temp file\n        Path(temp_file_path).unlink(missing_ok=True)\n        \n        return CommerceUploadResponse(\n            success=True,\n            batch_id=str(batch.id),\n            message=f"Awin data processed successfully. {batch.processed_records} records imported.",\n            source_type="awin",\n            estimated_records=batch.total_records\n        )\n        \n    except Exception as e:\n        logger.error(\n            "Awin import failed",\n            batch_id=str(batch_id),\n            filename=file.filename,\n            error=str(e),\n            exc_info=True\n        )\n        \n        # Clean up temp file on error\n        temp_file_path = f"/tmp/awin_import_{batch_id}_{file.filename}"\n        Path(temp_file_path).unlink(missing_ok=True)\n        \n        return CommerceUploadResponse(\n            success=False,\n            batch_id=str(batch_id),\n            message=f"Awin import failed: {str(e)}",\n            source_type="awin"\n        )\n\n\n@router.post("/upload/retailer/{retailer_name}", response_model=CommerceUploadResponse) \nasync def upload_retailer_data(\n    retailer_name: str,\n    file: UploadFile = File(...),\n    import_name: Optional[str] = Form(None),\n    db_session: AsyncSession = Depends(get_db_session),\n    current_user = Depends(require_admin_role)\n):\n    """Upload retailer data using the Large Retailer Import Service"""\n    \n    supported_retailers = ["nike", "adidas", "puma", "jordan", "newbalance", "converse", "vans"]\n    if retailer_name.lower() not in supported_retailers:\n        raise HTTPException(status_code=400, detail=f"Retailer '{retailer_name}' not supported")\n    \n    # File validation\n    if not file.filename.endswith(('.csv', '.json', '.jsonl')):\n        raise HTTPException(status_code=400, detail="Only CSV, JSON, and JSONL files are supported")\n    \n    if file.size and file.size > 1000 * 1024 * 1024:  # 1GB limit\n        raise HTTPException(status_code=400, detail="File too large. Maximum size is 1GB")\n    \n    try:\n        # Save uploaded file temporarily\n        file_content = await file.read()\n        temp_file_path = f"/tmp/retailer_import_{retailer_name}_{uuid4()}_{file.filename}"\n        \n        with open(temp_file_path, "wb") as temp_file:\n            temp_file.write(file_content)\n        \n        # Use Large Retailer Import Service\n        service = create_retailer_import_service(db_session)\n        \n        # Determine import method based on file type\n        if file.filename.endswith('.csv'):\n            batch_id = await service.import_csv_file(\n                file_path=temp_file_path,\n                retailer_name=retailer_name.title(),\n                import_name=import_name or f"{retailer_name.title()} Import - {datetime.now().date()}"\n            )\n        elif file.filename.endswith(('.json', '.jsonl')):\n            batch_id = await service.import_json_file(\n                file_path=temp_file_path,\n                retailer_name=retailer_name.title(),\n                import_name=import_name or f"{retailer_name.title()} Import - {datetime.now().date()}"\n            )\n        else:\n            raise HTTPException(status_code=400, detail="Unsupported file format")\n        \n        # Clean up temp file\n        Path(temp_file_path).unlink(missing_ok=True)\n        \n        return CommerceUploadResponse(\n            success=True,\n            batch_id=str(batch_id),\n            message=f"Retailer import initiated successfully for {retailer_name.title()}",\n            source_type=f"retailer_{retailer_name.lower()}"\n        )\n        \n    except Exception as e:\n        logger.error(\n            "Retailer import failed",\n            retailer_name=retailer_name,\n            filename=file.filename,\n            error=str(e),\n            exc_info=True\n        )\n        \n        # Clean up temp file on error\n        if 'temp_file_path' in locals():\n            Path(temp_file_path).unlink(missing_ok=True)\n        \n        return CommerceUploadResponse(\n            success=False,\n            batch_id=str(uuid4()),\n            message=f"Retailer import failed: {str(e)}",\n            source_type=f"retailer_{retailer_name.lower()}"\n        )\n\n\n@router.get("/status/{batch_id}", response_model=CommerceBatchStatus)\nasync def get_commerce_batch_status(\n    batch_id: UUID,\n    db_session: AsyncSession = Depends(get_db_session)\n):\n    """Get status of a commerce import batch"""\n    \n    try:\n        from shared.database.models import ImportBatch\n        from shared.repositories.base_repository import BaseRepository\n        \n        batch_repo = BaseRepository(ImportBatch, db_session)\n        batch = await batch_repo.get_by_id(batch_id)\n        \n        if not batch:\n            raise HTTPException(status_code=404, detail=f"Batch {batch_id} not found")\n        \n        # Calculate progress\n        progress = 0.0\n        if batch.total_records and batch.total_records > 0:\n            progress = (batch.processed_records or 0) / batch.total_records * 100.0\n        elif batch.status in ["completed", "finished"]:\n            progress = 100.0\n            \n        return CommerceBatchStatus(\n            batch_id=str(batch.id),\n            source_type=batch.source_type or "unknown",\n            status=batch.status or "pending",\n            progress=progress,\n            processed_records=batch.processed_records or 0,\n            failed_records=batch.error_records or 0,\n            total_records=batch.total_records,\n            memory_usage_mb=1024.0,  # Mock value - would be real in production\n            current_stage="Processing",\n            error_message=batch.error_message,\n            created_at=batch.created_at.isoformat() if batch.created_at else datetime.now().isoformat(),\n            completed_at=batch.completed_at.isoformat() if batch.completed_at else None\n        )\n        \n    except Exception as e:\n        logger.error(f"Failed to get batch status: {e}")\n        raise HTTPException(status_code=500, detail=f"Failed to get batch status: {str(e)}")\n\n\n@router.delete("/cancel/{batch_id}")\nasync def cancel_commerce_import(\n    batch_id: UUID,\n    db_session: AsyncSession = Depends(get_db_session),\n    current_user = Depends(require_admin_role)\n):\n    """Cancel an active commerce import"""\n    \n    try:\n        # This would integrate with the Large Retailer Service cancel functionality\n        service = create_retailer_import_service(db_session)\n        cancelled = await service.cancel_import(batch_id)\n        \n        if cancelled:\n            return {"success": True, "message": f"Import {batch_id} cancelled successfully"}\n        else:\n            return {"success": False, "message": f"Failed to cancel import {batch_id}"}\n            \n    except Exception as e:\n        logger.error(f"Failed to cancel import: {e}")\n        raise HTTPException(status_code=500, detail=f"Failed to cancel import: {str(e)}")\n\n\n@router.get("/analytics/summary")\nasync def get_commerce_analytics_summary(\n    db_session: AsyncSession = Depends(get_db_session)\n):\n    """Get summary analytics for commerce intelligence platform"""\n    \n    try:\n        from sqlalchemy import func, select\n        \n        # Get import statistics\n        query = select(\n            func.count(ImportBatch.id).label('total_imports'),\n            func.sum(ImportBatch.processed_records).label('total_records'),\n            func.count(ImportBatch.id).filter(ImportBatch.status == 'completed').label('successful_imports'),\n            func.count(ImportBatch.id).filter(ImportBatch.status == 'failed').label('failed_imports')\n        )\n        \n        result = await db_session.execute(query)\n        stats = result.first()\n        \n        return {\n            "total_imports": stats.total_imports or 0,\n            "total_records_processed": stats.total_records or 0,\n            "successful_imports": stats.successful_imports or 0,\n            "failed_imports": stats.failed_imports or 0,\n            "success_rate": (stats.successful_imports / stats.total_imports * 100) if stats.total_imports else 0,\n            "platform_status": "operational"\n        }\n        \n    except Exception as e:\n        logger.error(f"Failed to get analytics summary: {e}")\n        return {\n            "total_imports": 0,\n            "total_records_processed": 0,\n            "successful_imports": 0,\n            "failed_imports": 0,\n            "success_rate": 0,\n            "platform_status": "error"\n        }